\chapter{Methods}\label{sec:methods}

The aim of this thesis is to use inverse design to find a phononic beamsplitter,
a task that can be divided into three parts: 
First, some definitions of what
should be designed and what constitutes a ``good'' design needs to be made.
Second, we need a way to calculate the gradient of the ``goodness'' with respect
to the design.
And lastly, we need a gradient based optimization algorithm to find the optimal
design.
All of this will be described in this chapter.

\section{Design}

The device design to be optimized can be seen in \cref{fig:bs-design}.
The input and output waveguides consists of unit cells like the one in
\cref{fig:unitcell}.
The values for the parameters in the sketch are given in \cref{tab:params}.
The reason for using this mode in this waveguide is that it has been shown to be
interesting for avoiding mechanical leakage into the substrate on which it is
clamped, as well as retaining a high optomechanical
coupling.\cite{kolvik_clamped_2023}

Inside the design area, there can be one of two kinds of designs.
The first is a \emph{continuous design}, meaning that the material parameters
$\rho$ and $C_{ijkl}$ are continuously varying. The range of values that they
can take are between the density and elasticity of pure silicon and that of air.
Any in-between values are obviously not something that can be physically
realized, but it is useful as a first step in the optimization.
This is parametrized through the \emph{design field}, $p$, which takes values
between 0, which means pure air, and 1, which means pure silicon.
The second kind is a binary design, where each point either has silicon or not
and there are no in-between values.
This is accomplished using level-set methods, which will be explained in
\cref{sec:level-set}.

Because the device is completely symmetric, only one half of it needs to be
modeled, and the other half is extrapolated with a symmetry boundary condition.

\begin{figure}[htpb]
	\centering
	\input{chapters/methods/bs-design.tex}
	\caption{
		Device design to be optimized.
		At the red line, a wave traveling right is excited.
		The output is measured over the blue unit cells.
		The dashed unit cells are \glspl{pml}.
		The large, rectangular design area has dimensions $d_x \times d_y \times
		h$.
	}
	\label{fig:bs-design}
\end{figure}

\begin{table}[htpb]
	\centering
	\caption{%
		Values for the geometric parameters of the device.
		Reference \cref{fig:bs-design,fig:unitcell} for what the quantities
		mean.
	}%
	\label{tab:params}

	\begin{tabular}{cc}
		\toprule
		Parameter & value\\
		\midrule
		$a$ & \qty{187}{\nm}\\
		$w$ & \qty{187}{\nm}\\
		$h_x$ & \qty{153.5}{\nm}\\
		$h_y$ & \qty{49.5}{\nm}\\
		$h$ & \qty{220}{\nm}\\
		$d_x$ & $6 w$\\
		$d_y$ & $4 w$\\
		$s$ & $3 w$\\
		\bottomrule
	\end{tabular}
\end{table}

\subsection{Objective function}

The figure of merit of the device is how much of the input excitation gets transmitted
into the output beams.
Furthermore, all of the excitation of the output waveguide should be in the same
mode that was excited at the input.
Therefore, a mode overlap integral is used:
\begin{equation}
	I = \int_{\Omega_1} \vec{u}(\vec{x}) \cdot \vec{u}_m^*(\vec{x}) \dl{\vec x},
\end{equation}
where $\vec u_m$ is the shape of the mode (\cref{fig:ms1}).
Because we are not interested in the phase of the output waves,
the absolute value squared of the overlap integral is taken as the objective
function,
\begin{equation}
	\fobj = \abs{I}^2 = I I^*.
\end{equation}
This will be maximal when the excitation of the mode $m$ in the output
waveguide is maximized, regardless of which phase it has.

The functional derivative of $\fobj$ with respect to $p$ then becomes
\begin{align}
	\diff.f.{\fobj}{p}(x) &= \diff.f.{I}{p}(x) I^* + I\diff.f.{I^*}{p}(x)\\
	&= \diff.f.{I}{p}(x) I^* + \left(I^*\diff.f.{I}{p}(x)\right)^*\\
	&= 2\Re\left(\diff.f.{I}{p}(x) I^*\right).
\end{align}
The derivative of $I$ was derived in \cref{sec:spec_der}.

\subsection{Excitation}\label{sec:excitation_method}

In order to excite the input waveguide in the desired mode,
the stress on the boundary of a unit cell was exported from a unit cell
eigenmode simulation with $k=0.9 \pi / a$ and applied to the boundary marked in red in
\cref{fig:bs-design}.
Since the frequency is perfectly controlled, this should excite only the desired
mode, since that is the only permitted mode close by as seen in the band diagram
in \cref{fig:banddiagram}.

In order to confirm that the excitation was indeed fully in the desired mode, a
separate model with only a waveguide with 200 unitcells was created.
After applying the excitation and running the simulation,
the proportion of the excitation that ended up in the desired mode was
calculated.
This was done by first calculating the mode overlap integral
$\int \vec u \vec u_m^* \dl{\vec x}$
and comparing that to the norm of the displacement field
$\int \vec u \vec u^* \dl{\vec x}$.
If we write $\vec u$ as $\vec u = a \vec u_m + b \vec u_r$ for some scalars $a$ and $b$,
then
$\int \vec u \vec u^* \dl{\vec x} = a\int \vec u \vec u_m^*\dl{\vec x} + b\int
\vec u \vec u_r^*\dl{\vec x}$.
And assuming $\vec u_r$ is orthogonal to $\vec u_m$,
$a = \int \vec u \vec u_m^*\dl{\vec x} / \int \vec u_m \vec u_m^*\dl{\vec x}$,
which enables us to calculate $b$ as well.
The result was near perfect ($b < 0.03 a$) excitation of only the desired mode.
Since energy is proportional to
the square of the amplitude, $b < 0.03 a$ means that $>99.9 \%$ of the energy was
in the correct mode.
To obtain such high fidelity, it was important that the mesh used for the
unitcells in the wave guide was the same as the mesh in the unit cell
simulation.
High fidelity was also achieved if both meshes were made very fine, but such
fine meshes carries a prohibitively large computational cost.

\subsection{Perfectly Matched Layers (PMLs)}

Ideally, the input and outputs are infinite waveguides.
Unfortunately, simulating infinite waveguides would take infinite time.
Instead, \glspl{pml} are placed at the caps of the input and output waveguides.
The purpose of the \gls{pml} is to absorb any incoming waves without reflection,
which would make it act as if there was an infinite waveguide on the other side
into which the waves propagate indefinitely.
The way to accomplish this is to add an imaginary component to the density of
the material.
\todowrt{why does it work}
The imaginary part must be introduced smoothly,
otherwise the abrupt change in material
parameters would induce reflections anyway.
Therefore, the imaginary part is taken to be exponentially increasing,
starting at $y_0$ and continuing until the end of the waveguide, $n$ unit cells
later.
Furthermore, the curve is shifted vertically such that it is 0 at $y = y_0-n$,
and rescaled so that it is $\rho_\text{si} s$ at $y=y_0$.
\begin{equation}
	\rho_\text{im} = \rho_\text{si} \cdot s \cdot
	\frac{e^{-\abs{y-y_0} / d} - e^{-n/d}}{1 - e^{-n/d}}
\end{equation}
\Cref{fig:pml_profile} shows the effect of changing these parameters on the
shape of the profile of the imaginary component.

\begin{figure}[htpb]
	\centering
	\includegraphics{chapters/methods/pml_profile.pdf}
	\caption{%
		This figure shows the effect of changing different parameters.
		The green curves shows changing $d$ while keeping the other parameters
		fixed, and the orange and blue show $s$ and $n$ respectively.
		Darker colour means higher value, and the last green curve coincides
		with the first orange, and the last orange with the first blue.
	}%
	\label{fig:pml_profile}
\end{figure}

There are three possible sources of reflections.
Firstly, if the transition from no imaginary component to some imaginary
component is too abrupt, that causes reflections.
Secondly, if the imaginary component is too small, the waves will not be
dampened completely when they reach the end of the \gls{pml} and thus reflect
off of that.
And lastly, if $d$ is small then there can be reflections from the steep
increase that happens some distance away from the beginning of the \gls{pml}.
See \cref{fig:banddiagram} for an illustration of where the different types of
reflections occur.

\tikzset{
	reflection/.pic={
		\draw[->] (-0.4, 0) -- (-0.1, 0) arc[radius=0.1, start angle=-90, end
		angle=90] --++ (-0.1, 0);
		\draw[dashed] (0,-3.1) -- (0,8.3);
	}
}
\begin{figure}[htpb]
	\centering
	\begin{tikzpicture}[domain=1:8]

		\draw[->,very thick] (-0.0,0) -- (8.2,0) node[right] {$y$};
		\draw[->,very thick] (0,-0.0) -- (0,4.2) node[above] {$\rho_\text{im}$};
		\draw[very thick] (1,0) -- (1,-0.10) node[below] {$y_0-n$};
		\draw[very thick] (7.9,0) -- (7.9,-0.10) node[below] {$y_0$};
		%\draw[very thin,color=gray] (-0.1,-1.1) grid (7.9,3.9);
		\clip (0.0, 0.0) rectangle (7.9,3.9);
		\draw[color=ForestGreen, very thick] (0,0) -- (1,0) --
			plot (\x,{0.40*(exp(\x/3)-exp(1/3))});
		\draw[color=Orange, very thick] (0,0) -- (1,0) --
			plot (\x,{0.10*(exp(\x/4)-exp(1/4))});
		\draw[color=NavyBlue, very thick] (0,0) -- (1,0) --
			plot (\x,{0.02*exp(2.0*(\x-4))});
		\draw[ForestGreen] (1.0, 0.3) pic {reflection};
		\draw[NavyBlue] (5.7, 0.8) pic {reflection};
		\draw[Orange] (7.9, 0.9) pic {reflection};
	\end{tikzpicture}
	\caption{%
		For the green curve, the initial sudden increase of the imaginary
		component of the density at the beginning of the \gls{pml} causes reflections.
		For the blue curve, the beginning of the \gls{pml} is smooth but there
		is an increase partway through sharp enough to cause reflections.
		For the orange curve, the \gls{pml} never becomes strong enough to
		completely dampen the waves, and they get reflected at the end.
	}%
	\label{fig:pml_reflections}
\end{figure}

It is desirable to make $n$ as small as possible while still eliminating all
reflections. In order to do so, a long waveguide with the same parameters as
used for the input and output waveguides in the beamsplitter design was created.
To discern where there was some component of the wave reflected, a fourier
transform of the displacement field was made.
The parameters controlling the shape of the $\rho_\text{im}$ curve were then
varied and an appropriate value was selected.

\subsection{Level-set}\label{sec:level-set}

Ultimately, we want our device to consist of regions of material and regions of
no material.
There are basically two ways of doing this.
The first, and perhaps most intuitive,
is to simply store the coordinates of the boundary between the filled and empty
regions.
In addition to storing the coordinates, one must also store which points
neighbour which.
The second method, which is the one used in this report, is called
the \emph{level-set method}.
In this method, the boundary is not directly stored, but rather is stored via an
\emph{implicit function}, $\phi(x)$, defined such that the boundary is the
0-isocontour of $\phi$, i.e.\ the points $x$ where $\phi(x)=0$.

There are two main advantages of using the level-set method rather than
directly storing the boundary points.
Firstly, when moving the boundary we would like to do so in the normal
direction, as moving it along itself has no effect.
Computing the normal direction of a directly stored boundary is slightly cumbersome,
though certainly achievable.
With level-set, moving the boundary in the normal direction is as easy as adding
a constant to the implicit function.
Secondly, while the boundary is changing, the resolution in one part might need
to be increased while the resolution in another needs to be decreased. Deciding
where and when to add new points is non-trivial when directly storing the
boundary. Furthermore, if two boundaries merge, or if one splits in two, points
need to be removed and the connectivities changed, which is quite complex.
\Cref{fig:direct_troubles} illustrates these problems with direct storage concretely.
Both of these issues are automatically handled with the level-set method.
\tododec{How? (Isn't it obvious?)}

\begin{figure}[htpb]
	\centering
	\input{chapters/methods/direct-troubles.tex}
	\caption{%
		Possible evolution of boundary. In the leftmost figure, the
		boundary is defined by pretty much evenly spaced points. In the center figure
		the boundaries have moved and the spacing is no longer even, and the
		right circle is very poorly resolved.
		The rightmost figure shows the boundary after the two circles moved
		closer together. Now there are multiple points that need to be removed,
		marked in red, and the connectivity of the points that remain must be
		changed such that the two boundaries are merged.
	}%
	\label{fig:direct_troubles}
\end{figure}
\begin{figure}[htpb]
	\centering
	\includegraphics{chapters/methods/signed_dist_example.pdf}
	\caption{%
		Example of three signed distance functions for three different
		boundaries.
	}%
	\label{fig:signed_dist_example}
\end{figure}

There are of course a lot of possible functions $\phi(x)$ that have a given
boundary as it's 0-isocontour.
There is one choice that simplifies a lot of calculations though: the signed
distance function.
This function is defined as the distance from the closest point on the boundary,
with a plus sign if it is inside and a minus sign if it is outside the boundary.
See \cref{fig:signed_dist_example} for an example.
It has the advantage that if one wishes to locally shift the boundary some
length $s$ in the normal direction, then simply add $s$ to the function there.
\Cref{fig:add_shift} shows this effect in one dimension.
\todowrt{%
	Create another figure that shows it in two dimensions.
	I'm thinking a circular boundary, and adding $s$ in the left half and
	subtracting $s$ in the right half. Alternatively adding $s\cdot x$ (unit circle
	centered on 0) so that it will be smooth
}

\begin{figure}[htpb]
	\centering
	\begin{tikzpicture}[domain=0:3]
		\draw[very thin,color=gray] (-0.1,-2.1) grid (2.9,1.9);

		\draw[->] (-0.2,0) -- (3.2,0) node[right] {$x$};
		\draw[->] (0,-2.2) -- (0,2.2) node[above] {$\phi$};
		\draw[color=blue!50, dashed, very thick] plot (\x,{\x-2})
			node[right] {$\phi(x)$};
		\draw[color=blue, very thick] plot (\x,{\x-1})
			node[right] {$\phi(x)+s$};
		\filldraw[color=blue!50] (2,0) circle[radius=2pt];
		\filldraw[color=blue]    (1,0) circle[radius=2pt];
		\draw[color=red, ->, very thick] (1.9,0) --
			node[below] {$s$}
			(1.1,0);
	\end{tikzpicture}
	\caption{Adding $s$ to the signed distance function shifts boundary by
	$s$.}%
	\label{fig:add_shift}
\end{figure}

Using a signed distance function means that a gradient descent step can be taken
by simply adding the gradient field to the signed distance field.
However, there are some pitfalls that must be avoided.
Firstly, the gradient needs to be rescaled so that the boundary moves
an appropriate distance.
This has been done such that the boundary moves maximally \qty{1}{\nm}.
\todoblk[noinline]{check this number before finalizing, I change it every now and then}
Secondly, since the gradient is occasionally sharply peaked somewhere which may
not lie near the boundary, only the gradient near the boundary is actually added
to the signed distance field.
After performing this addition, what was previously a signed distance field will
now no longer be that, and thus the signed distance field is recalculated from
the new boundary.
This recalculation comes with a performance penalty, but since the COMSOL
simulations are orders of magnitude slower than all other parts of the
optimization, this is of little concern.


\section{Optimization}\label{sec:m_optimization}

For the optimization in the case of continuous optimization, the \gls{adam}
algorithm with one modification: a global learning rate was employed rather than
individual learning rates. The reasoning for this was that individual learning
rates would give jagged contours, which wouldn't be properly resolved by the
meshing. Practically this modification means that \mintinline{Python}+v+ is a
scalar and is set to \mintinline{Python}{(1-beta_2)*np.mean(g**2) + beta_2 * v}
in \cref{lst:adam}.
The optimization was run and continually monitored, and once convergence was
visually confirmed through looking at the plot of $\fobj$ by iteration, it was terminated.
A few different values for the $\beta$:s were tried, and in the end
$\beta_1=0.9$ and $\beta_2 = 0.95$ were chose. However, it seemed that the
evolution were not too sensitive to this choice.
$\alpha$ was taken to be \num{2e-3}, because that is large enough that $p$
could change from 0 to 1 in 500 iterations, which was deemed an appropriate
timescale since that took about one day.

The final step of the optimization was to use level-set for the design.
However, just using the final device of the continuous optimization for the
initial point of the level-set optimization would be a very large
change, and there is no reason to expect that the resulting level-set design
would be close to a design with good performance.
Therefore, once the continuous optimization had converged, a sigmoid function
was applied to the design field $p$ before $\rho$ and $C_{ijkl}$ were set:
\begin{align}
	\rho(\vec x) &= \rho_\text{si} \sigma_r(p(\vec x)),
	&
	C_{ijkl}(\vec x) &= C_{ijkl}^\text{si} \sigma_r(p(\vec x)),
	&
	\sigma_r(p) = \frac{1}{1+e^{-(p-0.5)/r}}.
\end{align}
and then the optimization was restarted.
This makes the design closer and closer to being binary, which means that the
step to level-set designs aren't as significant and hopefully the initial design
for the level-set optimization is not too far from a design with good performance.

Once that had been repeated a couple of times, the level-set design was
initialized using the final design of the continuous optimization, and the
level-set optimization was run.

\section{Simulations}

In this section I will detail some of the practicalities of performing the
simulations.
The simulation software used was COMSOL version 6.0.
First, a unit cell with periodic boundary conditions was simulated.
From that I obtain:
\begin{itemize}
	\item the mode shape, used to calculate the component of the displacement
		field in the desired mode,
	\item the stress at the boundary, used as the force exciting the input
		waveguide,
	\item the frequency at which to excite in order to obtain a traveling wave
		with the desired wave vector.
	\item a mesh to be used when meshing the unit cells in the waveguides.
\end{itemize}

For the continuous optimization, the basic procedure went
\begin{enumerate}
	\item Through the COMSOL-Matlab API, a beamsplitter model was made.
		The excitation force profile as well as the unit cell mesh and the mode
		shape was imported from the unit cell simulation.
	\item A semi-random initial design field $p$ was created. This was done by
		drawing a sample from a gaussian process, which means that the characteristic
		length scale that the design varies on could be controlled.
	\item\label{it:sigmoid} If the sigmoid function was to be used in this optimization, it was
		applied to the design field, and the result was saved to a different
		variable, that I call the interpolation field.
	\item The interpolation field was imported to the COMSOL model, and the
		material parameters adjusted proportional to said field.
	\item Both forward and backward simulations were run and the gradient was
		calculated and exported to Matlab.
	\item With the gradient, the design field was updated and the algorithm
		returns to step~\ref{it:sigmoid}.
\end{enumerate}

For the level-set optimization, the procedure was basically the same, with some
minor differences:
\begin{enumerate}
	\item Through the COMSOL-Matlab API, a beamsplitter model was made.
		The excitation force profile as well as the unit cell mesh and the mode
		shape was imported from the unit cell simulation.
	\item An initial signed distance field $s$ was created.
		This was done by finding the $p=0.5$ isocontour from the final iteration
		of the continuous optimization, and initializing a signed distance field
		from that.
	\item\label{it:import} The zero isocontour of the signed distance field was imported into
		the COMSOL model and a geometry was built from that.
	\item Both forward and backward simulations were run and the gradient was
		calculated and exported to Matlab.
	\item With the gradient, the signed distance field was updated and the algorithm
		returns to step~\ref{it:import}.
		Note that as part of the update, the signed distance field was
		reinitialized so that it would not lose its properties.
\end{enumerate}
